{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Category Data Review\n",
    "\n",
    "Load the news category data into the memory. It takes a few minutes and please be pacient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News category data load completed. Total 200847 recorders.\n"
     ]
    }
   ],
   "source": [
    "from NewsCategoryData import NewsCategory\n",
    "from NewsCategoryData import LABEL_DIC\n",
    "from NewsCategoryData import LABEL_LIST\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "data = NewsCategory(batch_size=BATCH_SIZE)\n",
    "print(\"News category data load completed. Total %d recorders.\"%len(data.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run below codes to print all the labels and label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIME:0\tENTERTAINMENT:1\tWORLD NEWS:2\tIMPACT:3\tPOLITICS:4\tWEIRD NEWS:5\n",
      "BLACK VOICES:6\tWOMEN:7\tCOMEDY:8\tQUEER VOICES:9\tSPORTS:10\n",
      "BUSINESS:11\tTRAVEL:12\tMEDIA:13\tTECH:14\tRELIGION:15\n",
      "SCIENCE:16\tLATINO VOICES:17\tEDUCATION:18\tCOLLEGE:19\tPARENTS:20\n",
      "ARTS & CULTURE:21\tSTYLE:22\tGREEN:23\tTASTE:24\tHEALTHY LIVING:25\n",
      "THE WORLDPOST:26\tGOOD NEWS:27\tWORLDPOST:28\tFIFTY:29\tARTS:30\n",
      "WELLNESS:31\tPARENTING:32\tHOME & LIVING:33\tSTYLE & BEAUTY:34\tDIVORCE:35\n",
      "WEDDINGS:36\tFOOD & DRINK:37\tMONEY:38\tENVIRONMENT:39\tCULTURE & ARTS:40\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0 \n",
    "for label in LABEL_DIC:\n",
    "    if i == 5:\n",
    "        print(label+\":\"+str(LABEL_DIC[label]))\n",
    "        i = 0\n",
    "    else:\n",
    "        print(label+\":\"+str(LABEL_DIC[label]), end=\"\\t\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run below code to show 10 news title at specific label\n",
    "Input the index of label you want to review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input a label index(0-40): 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEER VOICES Queer Eye Star Bobby Berk Gave Me A Desk Makeover - - And It Was Incredible \n",
      "QUEER VOICES Older Gay Men Try Out New Gay Slang In This Hilarious Video \n",
      "QUEER VOICES How RuPaul ’ s Drag Race Is Teaching Straight People About Queer Culture \n",
      "QUEER VOICES Tig Notaro Tells Ellen DeGeneres About Her Sons Passion For Trash \n",
      "QUEER VOICES Stormy Daniels Thanks ‘ Wonderful Gay Dads ’ As West Hollywood Hands Her Keys To City \n",
      "QUEER VOICES Can You Believe ? Queer Eye Season 2 Drops Next Month \n",
      "QUEER VOICES Gay Man Denied Marriage License By Kim Davis Loses Bid To Unseat Her \n",
      "QUEER VOICES More Americans Than Ever Support Same - Sex Marriage \n",
      "QUEER VOICES GLAADs Movie Report Finds Troubling Drop In LGBTQ Representation \n",
      "QUEER VOICES Sephora Now Offers In - Store Beauty Classes For Trans , Nonbinary Community \n",
      "QUEER VOICES Sarah Paulson Is Unapologetic About 32 - Year Age Gap With Girlfriend Holland Taylor \n",
      "QUEER VOICES Family Of Gay Man Found Critically Injured Near Amtrak Route Wants Answers \n",
      "QUEER VOICES Caitlyn Jenner : Trump Is The Worst President We Have Ever Had On LGBTQ Rights \n",
      "QUEER VOICES Boy Scout Allegedly Booted From Store Because Company Wont Support Homos \n",
      "QUEER VOICES Bill Konigsberg Explores A New Side Of The Gay Experience In His Latest Book \n",
      "QUEER VOICES Alone In The Game Shows Biggest Hurdles For LGBTQ Athletes Exist Off The Field \n",
      "QUEER VOICES French Digital Minister Comes Out As Gay To Fight Homophobia \n",
      "QUEER VOICES Belgian Transgender Ballet Drama Wins Big At Cannes Film Festival \n",
      "QUEER VOICES 86 - Year - Old Gay Man Proves Youre Never Too Old To Attend Your First Pride \n",
      "QUEER VOICES Transphobic Congressional Hopeful Berates Person Inside Public Restroom \n",
      "QUEER VOICES Singer Ryan Amador Says Loverboy Is His Second Coming Out \n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_SHOW = 20\n",
    "\n",
    "def is_int(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "index = 0\n",
    "\n",
    "while True:\n",
    "    input_value = input(\"Please input a label index(0-40):\") \n",
    "    if is_int(input_value):\n",
    "        index = int(input_value)\n",
    "        if index <=40 or index >=0:\n",
    "            break\n",
    "        \n",
    "icount = 0\n",
    "\n",
    "for i in range(data.max_recorder):\n",
    "    if data.label[i] == index:\n",
    "        news_title = \"\"\n",
    "        for word in data.data[i]:\n",
    "            news_title += word + \" \"\n",
    "        print(LABEL_LIST[data.label[i]], news_title)\n",
    "        icount += 1\n",
    "        if icount > MAX_SHOW:\n",
    "            break\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a model accuracy\n",
    "The result will be saved in list **prediction** and text file **prediction.log**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200847\n",
      "200847\n",
      "WARNING:tensorflow:From /home/ubuntu/Notebooks/MachineLearningStudy/NLP_CS224n/NewsCategory/Run_Prediction.py:67: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/Notebooks/MachineLearningStudy/NLP_CS224n/NewsCategory/Run_Prediction.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/Notebooks/MachineLearningStudy/NLP_CS224n/NewsCategory/Run_Prediction.py:69: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/python3-tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_save/news_category-200000\n",
      "200847\n",
      "200847\n",
      "200847\n",
      "200847\n"
     ]
    }
   ],
   "source": [
    "import Run_Prediction as rp\n",
    "def save_prediction(prediction, file_name):\n",
    "    fo = open(file_name, \"w+\")\n",
    "    for item in prediction:\n",
    "        fo. write(str(item)+\"\\n\")\n",
    "    fo.close()\n",
    "MODEL_FILE = 'news_category-100000.meta'\n",
    "ckpt_dir = './ckpt_save/'\n",
    "prediction_1 = rp.run_cnn_model(ckpt_dir,MODEL_FILE)\n",
    "print(len(prediction_1))\n",
    "\n",
    "word_matrix_file = \"naive_bayes_word_matrix.csv\"\n",
    "prediction_2 = rp.run_naive_bayes_model(word_matrix_file)\n",
    "print(len(prediction_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.42697177453485\n",
      "62.20356788998591\n"
     ]
    }
   ],
   "source": [
    "def cal_accuracy(data, prediction):\n",
    "    accuracy = 0\n",
    "    for i  in range(data.max_recorder):\n",
    "        if prediction[i] == data.label[i]:\n",
    "            accuracy += 1\n",
    "    return accuracy/data.max_recorder\n",
    "print(cal_accuracy(data,prediction_1)*100)\n",
    "print(cal_accuracy(data,prediction_2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the accuracy of each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(inf, 10000), (10000, 5000), (5000, 2000), (2000, 1000), (1000, 0)]\n",
      "ENTERTAINMENT:\t  71.62 % \t 16058 \t8.00 %\n",
      "POLITICS:\t  81.57 % \t 32738 \t16.30 %\n",
      "WELLNESS:\t  75.54 % \t 17827 \t8.88 %\n",
      "********************\n",
      "COMEDY:\t  20.70 % \t 5175 \t2.58 %\n",
      "QUEER VOICES:\t  51.91 % \t 6313 \t3.14 %\n",
      "BUSINESS:\t  34.35 % \t 5936 \t2.96 %\n",
      "TRAVEL:\t  72.61 % \t 9887 \t4.92 %\n",
      "HEALTHY LIVING:\t  8.99 % \t 6694 \t3.33 %\n",
      "PARENTING:\t  55.40 % \t 8677 \t4.32 %\n",
      "STYLE & BEAUTY:\t  71.69 % \t 9649 \t4.80 %\n",
      "FOOD & DRINK:\t  72.33 % \t 6226 \t3.10 %\n",
      "********************\n",
      "CRIME:\t  56.06 % \t 3405 \t1.70 %\n",
      "WORLD NEWS:\t  5.37 % \t 2177 \t1.08 %\n",
      "IMPACT:\t  13.21 % \t 3459 \t1.72 %\n",
      "WEIRD NEWS:\t  23.82 % \t 2670 \t1.33 %\n",
      "BLACK VOICES:\t  12.12 % \t 4528 \t2.25 %\n",
      "WOMEN:\t  20.72 % \t 3490 \t1.74 %\n",
      "SPORTS:\t  59.09 % \t 4884 \t2.43 %\n",
      "MEDIA:\t  21.32 % \t 2814 \t1.40 %\n",
      "TECH:\t  37.80 % \t 2082 \t1.04 %\n",
      "RELIGION:\t  39.69 % \t 2555 \t1.27 %\n",
      "SCIENCE:\t  41.18 % \t 2178 \t1.08 %\n",
      "PARENTS:\t  18.00 % \t 3955 \t1.97 %\n",
      "STYLE:\t  21.07 % \t 2254 \t1.12 %\n",
      "GREEN:\t  27.84 % \t 2622 \t1.31 %\n",
      "TASTE:\t  14.17 % \t 2096 \t1.04 %\n",
      "THE WORLDPOST:\t  52.18 % \t 3664 \t1.82 %\n",
      "WORLDPOST:\t  15.83 % \t 2578 \t1.28 %\n",
      "HOME & LIVING:\t  57.74 % \t 4195 \t2.09 %\n",
      "DIVORCE:\t  49.94 % \t 3426 \t1.71 %\n",
      "WEDDINGS:\t  59.38 % \t 3651 \t1.82 %\n",
      "********************\n",
      "LATINO VOICES:\t  2.48 % \t 1129 \t0.56 %\n",
      "EDUCATION:\t  16.43 % \t 1004 \t0.50 %\n",
      "COLLEGE:\t  19.06 % \t 1144 \t0.57 %\n",
      "ARTS & CULTURE:\t  9.86 % \t 1339 \t0.67 %\n",
      "GOOD NEWS:\t  19.31 % \t 1398 \t0.70 %\n",
      "FIFTY:\t  3.64 % \t 1401 \t0.70 %\n",
      "ARTS:\t  17.43 % \t 1509 \t0.75 %\n",
      "MONEY:\t  20.09 % \t 1707 \t0.85 %\n",
      "ENVIRONMENT:\t  13.98 % \t 1323 \t0.66 %\n",
      "CULTURE & ARTS:\t  16.41 % \t 1030 \t0.51 %\n",
      "********************\n",
      "********************\n",
      "[(inf, 10000), (10000, 5000), (5000, 2000), (2000, 1000), (1000, 0)]\n",
      "ENTERTAINMENT:\t  60.33 % \t 16058 \t8.00 %\n",
      "POLITICS:\t  64.25 % \t 32738 \t16.30 %\n",
      "WELLNESS:\t  50.91 % \t 17827 \t8.88 %\n",
      "********************\n",
      "COMEDY:\t  55.38 % \t 5175 \t2.58 %\n",
      "QUEER VOICES:\t  62.84 % \t 6313 \t3.14 %\n",
      "BUSINESS:\t  54.45 % \t 5936 \t2.96 %\n",
      "TRAVEL:\t  68.12 % \t 9887 \t4.92 %\n",
      "HEALTHY LIVING:\t  51.60 % \t 6694 \t3.33 %\n",
      "PARENTING:\t  52.15 % \t 8677 \t4.32 %\n",
      "STYLE & BEAUTY:\t  69.46 % \t 9649 \t4.80 %\n",
      "FOOD & DRINK:\t  65.92 % \t 6226 \t3.10 %\n",
      "********************\n",
      "CRIME:\t  87.93 % \t 3405 \t1.70 %\n",
      "WORLD NEWS:\t  47.73 % \t 2177 \t1.08 %\n",
      "IMPACT:\t  57.10 % \t 3459 \t1.72 %\n",
      "WEIRD NEWS:\t  56.14 % \t 2670 \t1.33 %\n",
      "BLACK VOICES:\t  57.24 % \t 4528 \t2.25 %\n",
      "WOMEN:\t  56.22 % \t 3490 \t1.74 %\n",
      "SPORTS:\t  67.40 % \t 4884 \t2.43 %\n",
      "MEDIA:\t  64.29 % \t 2814 \t1.40 %\n",
      "TECH:\t  70.03 % \t 2082 \t1.04 %\n",
      "RELIGION:\t  66.26 % \t 2555 \t1.27 %\n",
      "SCIENCE:\t  61.80 % \t 2178 \t1.08 %\n",
      "PARENTS:\t  60.56 % \t 3955 \t1.97 %\n",
      "STYLE:\t  66.19 % \t 2254 \t1.12 %\n",
      "GREEN:\t  62.20 % \t 2622 \t1.31 %\n",
      "TASTE:\t  62.79 % \t 2096 \t1.04 %\n",
      "THE WORLDPOST:\t  64.68 % \t 3664 \t1.82 %\n",
      "WORLDPOST:\t  65.17 % \t 2578 \t1.28 %\n",
      "HOME & LIVING:\t  73.28 % \t 4195 \t2.09 %\n",
      "DIVORCE:\t  77.55 % \t 3426 \t1.71 %\n",
      "WEDDINGS:\t  78.14 % \t 3651 \t1.82 %\n",
      "********************\n",
      "LATINO VOICES:\t  65.01 % \t 1129 \t0.56 %\n",
      "EDUCATION:\t  70.22 % \t 1004 \t0.50 %\n",
      "COLLEGE:\t  70.72 % \t 1144 \t0.57 %\n",
      "ARTS & CULTURE:\t  58.40 % \t 1339 \t0.67 %\n",
      "GOOD NEWS:\t  67.67 % \t 1398 \t0.70 %\n",
      "FIFTY:\t  73.02 % \t 1401 \t0.70 %\n",
      "ARTS:\t  49.24 % \t 1509 \t0.75 %\n",
      "MONEY:\t  73.81 % \t 1707 \t0.85 %\n",
      "ENVIRONMENT:\t  68.93 % \t 1323 \t0.66 %\n",
      "CULTURE & ARTS:\t  49.71 % \t 1030 \t0.51 %\n",
      "********************\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy_by_label(prediction):\n",
    "    count_correct_by_category = [0 for item in LABEL_DIC]\n",
    "    count_total_by_category = [0 for item in LABEL_DIC]\n",
    "\n",
    "    for i in range(len(data.label)):\n",
    "        count_total_by_category[data.label[i]] += 1\n",
    "        if data.label[i] == prediction[i]:\n",
    "            count_correct_by_category[data.label[i]] += 1\n",
    "    accuracy = []\n",
    "    for i in range(len(count_correct_by_category)):\n",
    "        accuracy.append(count_correct_by_category[i]/count_total_by_category[i])\n",
    "\n",
    "    TRAIN_SAMPLE_LEVEL = [10000,5000,2000,1000]\n",
    "    train_sample_level = [(float('inf'), TRAIN_SAMPLE_LEVEL[0])]\n",
    "    for i in range(len(TRAIN_SAMPLE_LEVEL)-1):\n",
    "        train_sample_level.append((TRAIN_SAMPLE_LEVEL[i],TRAIN_SAMPLE_LEVEL[i+1]))\n",
    "    train_sample_level.append((TRAIN_SAMPLE_LEVEL[len(TRAIN_SAMPLE_LEVEL)-1],0))\n",
    "    print(train_sample_level)\n",
    "\n",
    "    for level in train_sample_level:\n",
    "        for i in range(len(count_correct_by_category)):\n",
    "            if count_total_by_category[i] <= level[0] and count_total_by_category[i] > level[1]:\n",
    "                print(\"%s:\\t  %.2f %% \\t %d \\t%.2f %%\"%(LABEL_LIST[i],accuracy[i]*100, count_total_by_category[i],count_total_by_category[i]/len(data.label)*100))\n",
    "        print(\"*\"*20)\n",
    "check_accuracy_by_label(prediction_1)\n",
    "check_accuracy_by_label(prediction_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the naive bayes word vectors. It takes a few minutes.\n",
      "[[2.6427e-05 3.1536e-04 0.0000e+00 1.4195e-04 3.4879e-03 1.7384e-04\n",
      "  2.6860e-04 1.5240e-03 8.8841e-04 2.8942e-04 7.1722e-05 1.4702e-04\n",
      "  0.0000e+00 9.5298e-04 4.5360e-05 1.2278e-04 0.0000e+00 5.3821e-04\n",
      "  2.0672e-04 1.7493e-04 2.2368e-04 5.7618e-04 3.7574e-04 1.1148e-04\n",
      "  1.4270e-04 6.2869e-05 4.9418e-05 1.2218e-04 4.0393e-05 3.0862e-04\n",
      "  0.0000e+00 0.0000e+00 1.1541e-05 0.0000e+00 2.3623e-04 0.0000e+00\n",
      "  5.2102e-05 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [5.2854e-04 6.8508e-04 2.8423e-04 5.6779e-05 2.6386e-04 2.4338e-04\n",
      "  3.2615e-04 8.3126e-05 1.0452e-04 2.3430e-04 1.9724e-04 2.1237e-04\n",
      "  2.1262e-04 1.9717e-04 3.1752e-04 1.2278e-04 1.6947e-04 2.3066e-04\n",
      "  2.0672e-04 0.0000e+00 1.2427e-04 2.5608e-04 4.1748e-05 1.4864e-04\n",
      "  4.7567e-05 1.1002e-04 2.4709e-04 6.1091e-05 4.4432e-04 7.7155e-05\n",
      "  2.0138e-04 1.4066e-04 1.3849e-04 3.9460e-04 1.7106e-04 1.1379e-04\n",
      "  1.8236e-04 1.2391e-04 1.1193e-04 1.3905e-04 2.6187e-04]\n",
      " [1.7125e-02 1.7399e-02 2.2576e-02 2.8333e-02 2.6957e-02 1.6376e-02\n",
      "  2.2620e-02 2.6850e-02 1.6340e-02 2.3347e-02 1.9616e-02 2.5615e-02\n",
      "  2.5663e-02 2.2017e-02 2.5447e-02 2.3124e-02 1.8854e-02 2.7603e-02\n",
      "  2.5013e-02 3.1488e-02 3.0271e-02 2.2215e-02 2.0373e-02 2.2185e-02\n",
      "  2.9016e-02 3.4138e-02 2.1843e-02 2.9140e-02 1.9469e-02 3.2636e-02\n",
      "  1.3828e-02 2.7454e-02 2.7133e-02 2.2433e-02 1.4166e-02 2.6144e-02\n",
      "  2.6468e-02 2.2799e-02 3.0108e-02 1.8285e-02 9.0782e-03]\n",
      " [1.0571e-04 8.6995e-05 3.6544e-04 3.4068e-04 2.7210e-04 6.9536e-05\n",
      "  1.3430e-04 8.3126e-05 3.4840e-05 2.7564e-04 2.5103e-04 2.4504e-04\n",
      "  7.4417e-05 1.6431e-04 2.2680e-04 2.0463e-04 2.1184e-04 0.0000e+00\n",
      "  4.1344e-04 5.2480e-04 9.9413e-05 6.4020e-05 3.3399e-04 1.4864e-04\n",
      "  1.4270e-04 3.7722e-04 2.4709e-04 2.4436e-04 2.0196e-04 4.6293e-04\n",
      "  1.3426e-04 2.8744e-04 1.3849e-04 2.5649e-04 8.1459e-05 4.5518e-04\n",
      "  2.6051e-05 1.0621e-04 1.1193e-04 1.3905e-04 8.7291e-05]\n",
      " [5.2854e-05 1.9574e-04 3.6544e-04 2.2712e-04 2.0614e-04 0.0000e+00\n",
      "  3.4534e-04 2.2167e-04 1.0452e-04 1.5160e-04 1.9724e-04 2.2870e-04\n",
      "  2.2325e-04 9.8584e-05 1.3608e-04 1.6371e-04 4.2367e-04 7.6888e-05\n",
      "  1.0336e-04 3.4986e-04 1.4912e-04 1.9206e-04 1.2525e-04 2.2297e-04\n",
      "  2.8540e-04 2.0433e-04 2.2238e-04 6.1091e-05 2.8275e-04 3.8577e-04\n",
      "  2.6851e-04 2.3852e-04 1.0387e-04 1.3811e-04 1.1404e-04 1.7069e-04\n",
      "  5.2102e-05 3.5403e-05 5.5963e-05 0.0000e+00 8.7291e-05]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 2.7485e-06 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [7.5846e-03 8.4331e-03 5.9688e-03 5.5644e-03 5.1232e-03 8.2400e-03\n",
      "  5.6789e-03 4.9044e-03 7.8041e-03 5.2234e-03 5.6660e-03 5.3418e-03\n",
      "  4.5713e-03 6.8023e-03 5.7607e-03 5.8116e-03 3.8131e-03 5.2284e-03\n",
      "  4.3411e-03 4.1984e-03 9.1212e-03 5.4417e-03 5.9283e-03 4.3850e-03\n",
      "  7.7534e-03 6.7742e-03 4.8183e-03 1.3745e-02 4.2412e-03 6.5581e-03\n",
      "  7.9211e-03 6.9109e-03 7.6634e-03 7.3001e-03 4.7165e-03 6.8561e-03\n",
      "  4.1421e-03 7.7355e-03 3.7495e-03 3.3373e-03 5.5866e-03]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 2.8390e-05 1.0994e-05 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.7930e-05 0.0000e+00\n",
      "  1.0631e-05 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.3784e-04 4.3497e-05 2.0302e-04 0.0000e+00 5.4970e-05 1.3907e-04\n",
      "  7.6742e-05 2.7709e-05 5.2259e-05 1.6538e-04 5.3791e-05 6.5343e-05\n",
      "  1.2119e-03 0.0000e+00 4.5360e-05 4.0927e-05 1.2710e-04 1.5378e-04\n",
      "  1.0336e-04 8.7466e-05 0.0000e+00 0.0000e+00 0.0000e+00 4.0877e-04\n",
      "  9.5134e-05 1.5717e-05 2.9651e-04 1.2218e-04 1.2118e-04 7.7155e-05\n",
      "  3.3564e-04 3.6695e-05 4.6165e-05 3.3541e-04 1.6292e-05 0.0000e+00\n",
      "  1.3026e-04 8.8507e-05 2.7981e-04 6.9527e-04 0.0000e+00]\n",
      " [2.6427e-05 2.1749e-05 2.0302e-04 2.2712e-04 2.1988e-04 0.0000e+00\n",
      "  7.6742e-05 1.1083e-04 1.5678e-04 5.5128e-05 5.3791e-05 9.8015e-05\n",
      "  0.0000e+00 1.6431e-04 4.5360e-05 1.2278e-04 0.0000e+00 7.6888e-05\n",
      "  1.0336e-04 4.3733e-04 0.0000e+00 6.4020e-05 4.1748e-05 1.4864e-04\n",
      "  0.0000e+00 7.8587e-05 1.2355e-04 0.0000e+00 8.0785e-05 0.0000e+00\n",
      "  0.0000e+00 4.8927e-05 0.0000e+00 1.9730e-05 3.2584e-05 2.8449e-05\n",
      "  0.0000e+00 0.0000e+00 5.5963e-05 6.9527e-05 0.0000e+00]\n",
      " [2.2992e-03 1.7671e-03 3.2483e-04 2.6119e-03 6.5965e-04 2.1904e-03\n",
      "  4.0481e-03 1.9396e-03 1.3344e-02 3.9555e-03 5.8633e-03 2.5811e-03\n",
      "  2.2899e-02 1.0516e-03 2.9030e-03 1.9235e-03 7.5838e-03 6.1510e-04\n",
      "  1.6537e-03 8.7466e-04 1.6900e-03 6.4020e-04 1.3359e-03 1.2635e-03\n",
      "  2.2832e-03 2.1847e-03 7.4127e-05 3.6655e-04 9.2903e-04 1.3888e-03\n",
      "  5.5716e-03 6.2748e-03 1.1195e-02 3.7270e-02 4.3972e-02 9.6441e-03\n",
      "  1.9408e-02 2.2870e-02 5.6522e-03 1.3975e-02 3.0988e-02]\n",
      " [9.2495e-04 2.7403e-03 2.6393e-03 4.0313e-03 3.4137e-03 3.9288e-03\n",
      "  2.3982e-03 5.3755e-03 2.9962e-03 3.0045e-03 2.1337e-03 4.3943e-03\n",
      "  2.7853e-03 2.4646e-03 3.9917e-03 4.1336e-03 3.1776e-03 4.5364e-03\n",
      "  4.6512e-03 5.7728e-03 5.0701e-03 4.8015e-03 4.3001e-03 4.0505e-03\n",
      "  6.4691e-03 5.1396e-03 2.5697e-03 1.9549e-03 2.6659e-03 3.0862e-03\n",
      "  3.0879e-03 3.9814e-03 4.5703e-03 2.7819e-03 2.6963e-03 2.9302e-03\n",
      "  2.8396e-03 3.7527e-03 4.3651e-03 2.5030e-03 1.3094e-03]\n",
      " [7.8224e-03 3.1345e-02 2.0099e-02 3.6254e-02 2.5611e-02 1.8914e-02\n",
      "  2.5670e-02 3.6437e-02 3.1251e-02 2.9466e-02 2.5963e-02 3.2378e-02\n",
      "  4.0982e-02 2.5205e-02 2.8259e-02 3.6056e-02 2.2836e-02 2.7680e-02\n",
      "  4.2584e-02 2.9651e-02 2.9973e-02 3.5980e-02 3.7949e-02 3.5712e-02\n",
      "  3.5533e-02 3.0287e-02 1.7148e-02 1.8327e-02 3.9989e-02 4.1509e-02\n",
      "  4.9473e-02 3.1270e-02 2.9949e-02 2.2788e-02 2.3599e-02 2.3925e-02\n",
      "  2.6702e-02 3.7899e-02 2.1937e-02 3.4068e-02 4.6875e-02]\n",
      " [0.0000e+00 2.7186e-05 0.0000e+00 0.0000e+00 5.2497e-04 0.0000e+00\n",
      "  3.8371e-05 1.9396e-04 1.2194e-04 1.3782e-05 0.0000e+00 1.6336e-05\n",
      "  0.0000e+00 9.8584e-05 0.0000e+00 4.0927e-05 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 4.9707e-05 6.4020e-05 8.3497e-05 3.7161e-05\n",
      "  9.5134e-05 1.5717e-05 2.4709e-05 0.0000e+00 0.0000e+00 1.5431e-04\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 5.7021e-05 0.0000e+00\n",
      "  2.6051e-05 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 5.4970e-06 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.5717e-05 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [5.5497e-04 4.4041e-04 7.3088e-04 7.6652e-04 7.4485e-04 4.5199e-04\n",
      "  3.2615e-04 8.8667e-04 8.7099e-04 7.0289e-04 5.1998e-04 1.2905e-03\n",
      "  7.9732e-04 4.6006e-04 4.9896e-04 1.2278e-03 5.9314e-04 6.9199e-04\n",
      "  1.2403e-03 1.3995e-03 8.6987e-04 6.4020e-04 5.4273e-04 8.5470e-04\n",
      "  8.5621e-04 1.4774e-03 2.9651e-04 3.0546e-04 7.2707e-04 7.7155e-04\n",
      "  8.0553e-04 1.7430e-03 1.5004e-03 1.1443e-03 1.1649e-03 1.8492e-03\n",
      "  8.3364e-04 1.1860e-03 1.8468e-03 4.1716e-04 2.6187e-04]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 2.7485e-06 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.4271e-03 2.2456e-03 3.2483e-03 6.2741e-03 3.7792e-03 5.1457e-03\n",
      "  2.4941e-03 5.4863e-03 3.6233e-03 5.2096e-03 2.9047e-03 7.1714e-03\n",
      "  5.4005e-03 3.7133e-03 5.1710e-03 7.7760e-03 7.9651e-03 2.7680e-03\n",
      "  1.3333e-02 6.2976e-03 4.6227e-03 2.7529e-03 3.1729e-03 5.3512e-03\n",
      "  3.6627e-03 7.7329e-03 1.5073e-03 1.6495e-03 7.9170e-03 5.1694e-03\n",
      "  4.3633e-03 1.3785e-02 1.0964e-02 3.5514e-03 5.6288e-03 1.5732e-02\n",
      "  7.8414e-03 5.6467e-03 1.0297e-02 5.7012e-03 1.6585e-03]\n",
      " [2.2992e-03 1.7671e-03 3.2483e-04 2.6119e-03 6.5415e-04 2.1904e-03\n",
      "  4.0481e-03 1.9396e-03 1.3361e-02 3.9555e-03 5.8453e-03 2.5811e-03\n",
      "  2.2899e-02 1.0516e-03 2.9030e-03 1.9235e-03 7.5838e-03 6.1510e-04\n",
      "  1.6537e-03 8.7466e-04 1.6900e-03 6.4020e-04 1.3359e-03 1.2635e-03\n",
      "  2.2832e-03 2.1847e-03 7.4127e-05 3.6655e-04 9.2903e-04 1.3888e-03\n",
      "  5.7730e-03 6.2748e-03 1.1195e-02 3.7250e-02 4.3963e-02 9.6726e-03\n",
      "  1.9408e-02 2.2852e-02 5.6522e-03 1.3975e-02 3.0988e-02]]\n",
      "x1 [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 2.1932e-66 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "x2 [2.1932e-66]\n",
      "predict [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4\n",
      "(41,)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import Run_Prediction as rp\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4,suppress =False)\n",
    "word_matrix_file = \"naive_bayes_word_matrix.csv\"\n",
    "word_matrix, word_list = rp.read_naive_bayes_word_vector(word_matrix_file)\n",
    "title_list = [['Hillary', 'Set', 'To', 'Move', 'Past', 'Prelims', 'With', 'Roosevelt', 'Island', 'Address', '(', 'Are', 'the', 'Clintons', 'Cynics', 'or', 'Realists', '?', ')']]\n",
    "for title in title_list:\n",
    "    naive_bayes_input = rp.naive_bayes_model(title, word_matrix, word_list)\n",
    "    print(naive_bayes_input)\n",
    "    print(naive_bayes_input.argmax())\n",
    "    print(naive_bayes_input.shape)\n",
    "    print(\"-\"*30)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Trainset and Testset \n",
    "\n",
    "For each category, 90% of recordes will be assigned as trainset and 10% will be assigned as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3405, 16058, 2177, 3459, 32738, 2670, 4528, 3490, 5175, 6313, 4884, 5936, 9887, 2814, 2082, 2555, 2178, 1129, 1004, 1144, 3955, 1339, 2254, 2622, 2096, 6694, 3664, 1398, 2578, 1401, 1509, 17827, 8677, 4195, 9649, 3426, 3651, 6226, 1707, 1323, 1030]\n",
      "200847\n"
     ]
    }
   ],
   "source": [
    "# First step to get the count of recorders for each category.\n",
    "\n",
    "def count_by_category(labels,class_mum):\n",
    "    count_by_cat_list = [0 for i in range(class_mum)]\n",
    "    for i in labels:\n",
    "        count_by_cat_list[i] += 1\n",
    "    return count_by_cat_list\n",
    "\n",
    "lst_count_by_category = count_by_category(data.label,len(LABEL_DIC))\n",
    "\n",
    "print(lst_count_by_category)\n",
    "\n",
    "total_data = 0\n",
    "for num in lst_count_by_category:\n",
    "    total_data += num\n",
    "print(total_data)\n",
    "\n",
    "#Generate trainset and testset\n",
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "count_train_by_category = [0 for i in range(len(LABEL_DIC))]\n",
    "\n",
    "for i in range(data.max_recorder):\n",
    "    if count_train_by_category[data.label[i]] <= lst_count_by_category[data.label[i]]*0.9:\n",
    "        train_data.append(data.data[i]) \n",
    "        train_label.append(data.label[i])\n",
    "        count_train_by_category[data.label[i]] += 1\n",
    "    else:\n",
    "        test_data.append(data.data[i]) \n",
    "        test_label.append(data.label[i])\n",
    "        \n",
    "# Now save the trainset and testset to the csv file.\n",
    "# For each recorder, there's label to mark whether it is belong to train or test set. \n",
    "fo = open(\"news_cat_train_test_data.csv\", \"w+\")\n",
    "writer = csv.writer(fo)\n",
    "writer.writerow(['title','label','train_or_test'])\n",
    "for i in range(len(train_data)):\n",
    "    writer.writerow([train_data[i],train_label[i],'train'])\n",
    "for i in range(len(test_data)):\n",
    "    writer.writerow([test_data[i],test_label[i],'test'])\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is to test a class to read news category data which is seperated by train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200847\n",
      "['The', 'Buffett', 'Rule', 'or', 'the', 'Lincome', 'Tax', '?'] 38\n",
      "['Setting', 'Sail', 'On', 'A', 'Schooner', 'For', 'A', 'Knitting', 'Vacation'] 12\n"
     ]
    }
   ],
   "source": [
    "from NewsCategoryData import NewsCategoryTrainTestSet\n",
    "\n",
    "dataset = NewsCategoryTrainTestSet(filepath = \"news_cat_train_test_data.csv\")\n",
    "for i in range(10000):\n",
    "    train_data, train_label = dataset.batch_test_set()\n",
    "    if len(train_data) != 100 or len(train_label) != 100:\n",
    "        print(len(train_data),len(train_label))\n",
    "print(train_data[0], train_label[0])   \n",
    "\n",
    "for i in range(10000):\n",
    "    test_data, test_label = dataset.batch_test_set()\n",
    "    if len(test_data) != 100 or len(test_label) != 100:\n",
    "        print(len(test_data),len(test_label))\n",
    "print(test_data[0], test_label[0])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below code will run the combined model to give category prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-9374289aa1b2>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-9374289aa1b2>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    [\"police\", \"defend\",\"\" aboriginal tent embassy raid]]\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import Run_Prediction as rp\n",
    "\n",
    "ckpt_dir = './ckpt_save_8/'\n",
    "model_file='news_category-200000.meta'\n",
    "\n",
    "word_matrix_file = \"naive_bayes_word_matrix.csv\"\n",
    "word_matrix, word_list = rp.read_naive_bayes_word_vector(word_matrix_file)\n",
    "\n",
    "ckpt_dir_combine = './ckpt_save/'\n",
    "graph_file = 'combined_new_category-50000.meta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load graph.\n",
      "Load model.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_save_8/news_category-200000\n",
      "./ckpt_save/combined_new_category-50000\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_save/combined_new_category-50000\n",
      "Restore model.\n",
      "2\n",
      "Load graph.\n",
      "Load model.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_save_8/news_category-200000\n",
      "./ckpt_save/combined_new_category-50000\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_save/combined_new_category-50000\n",
      "Restore model.\n",
      "4\n",
      "Load graph.\n",
      "Load model.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_save_8/news_category-200000\n",
      "./ckpt_save/combined_new_category-50000\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_save/combined_new_category-50000\n",
      "Restore model.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "title_list= [[\"aust\",\"addresses\",\"un\",\"security\",\"council\",\"over\", \"iraq\"],\n",
    "             [\"funds\",\"allocated\",\"for\",\"youth\",\"at\",\"risk\"],\n",
    "             [\"police\", \"defend\",\"aboriginal\",\"tent\",\"embassy\",\"raid\"]]\n",
    "for title in title_list:\n",
    "    cnn_logits = rp.one_cnn_model(title,ckpt_dir, model_file)\n",
    "    naive_bayes_input = rp.one_naive_bayes_model(title, word_matrix, word_list)\n",
    "    prediction = rp.one_combined_model(cnn_logits,naive_bayes_input,ckpt_dir_combine,graph_file)\n",
    "    print(prediction[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3-tensorflow-gpu] *",
   "language": "python",
   "name": "conda-env-python3-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
