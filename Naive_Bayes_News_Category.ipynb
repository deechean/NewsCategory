{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Naive Bayes to predict the News Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import threading\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "sys.path.append('../../common/')\n",
    "\n",
    "from train_log import train_log\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\" \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "\n",
    "FILE_NAME = 'News_Category_Dataset_v2.json'\n",
    "\n",
    "ckpt_dir = './ckpt_save/'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "log_dir = './log/'\n",
    "log = train_log(log_dir)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "CONTINUE = 1\n",
    "start_step = 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58834\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from NewsCategoryData import NewsCategory\n",
    "from NewsCategoryData import LABEL_LIST\n",
    "batch_size = 64\n",
    "max_length = 100\n",
    "data = NewsCategory(batch_size=batch_size,max_length=max_length)\n",
    "\n",
    "max_recorder = data.max_recorder\n",
    "word_dict = {}\n",
    "\n",
    "for i in range(max_recorder):\n",
    "    for word in data.data[i]:\n",
    "        if word.lower() in word_dict:\n",
    "            word_dict[word.lower()][data.label[i]] += 1\n",
    "        else:\n",
    "            word_dict[word.lower()] = [0 for i in range(len(LABEL_LIST))]\n",
    "            word_dict[word.lower()][data.label[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "word_list = {}\n",
    "word_matrix = []\n",
    "index = 0\n",
    "for word in word_dict:\n",
    "    word_list[word] = index \n",
    "    word_matrix.append(word_dict[word])\n",
    "    index += 1\n",
    "    \n",
    "word_matrix = np.asarray(word_matrix) \n",
    "word_matrix = np.divide(word_matrix,word_matrix.sum(axis=0))\n",
    "\n",
    "fo = open(\"naive_bayes_word_matrix.csv\", \"w+\")\n",
    "writer = csv.writer(fo)\n",
    "\n",
    "for key in word_list:\n",
    "    writer.writerow([key]+list(word_matrix[word_list[key]]))\n",
    "fo.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58834\n",
      "(58834, 41)\n"
     ]
    }
   ],
   "source": [
    "word_matrix_2 = []\n",
    "word_list_2 = {}\n",
    "fo = open(\"naive_bayes_word_matrix.csv\", \"r+\")\n",
    "reader = csv.reader(fo)\n",
    "index = 0\n",
    "for row in reader:\n",
    "    word_list_2[row[0]] = index\n",
    "    index += 1\n",
    "    m=[]\n",
    "    for data in row[1:]:\n",
    "        m.append(float(data))\n",
    "    word_matrix_2.append(m)\n",
    "word_matrix_2 = np.array(word_matrix_2)\n",
    "print(len(word_list_2))\n",
    "print(word_matrix_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate = 77.40 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "accuracy = 0\n",
    "icount = 0\n",
    "prediction = []\n",
    "for title in data.data:\n",
    "    y = np.array([1 for i in range(word_matrix.shape[1])], dtype=np.float32)\n",
    "    x = [] \n",
    "    for word in title:\n",
    "        x.append(word_matrix[word_list[word.lower()]])\n",
    "    y = np.asarray(x).prod(axis=0)   \n",
    "    #print(\"y=\",y)\n",
    "    prediction.append(y.argmax())\n",
    "    #print(prediction,data.label[icount])\n",
    "    if y.argmax() == data.label[icount]:\n",
    "        accuracy += 1\n",
    "    icount += 1\n",
    "print(\"Accuracy rate = %.2f %%\"%(accuracy/len(data.label)*100))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3-tensorflow-gpu] *",
   "language": "python",
   "name": "conda-env-python3-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
